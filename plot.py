Trainacc = [80.70656311862342, 85.77737170701994, 88.77721943048577, 89.09700015227654, 89.31018730013704,
            89.61474036850922, 89.55382975483478, 90.05634231764886, 90.17816354499772, 90.43703365311406,90.37612303943962, 90.75681437490482, 90.95477386934674, 91.47251408557942, 91.30500989797471, 91.60956296634689, 91.39637581848638, 91.68570123343993, 91.59433531292828, 91.70092888685853, 91.65524592660272, 91.8227501142074, 91.80752246078879, 91.92934368813765, 91.85320542104462, 92.09684787574236, 92.05116491548652, 92.21866910309122, 92.27957971676565, 92.59936043855642, 92.53844982488198, 92.79731993299832, 92.96482412060301, 92.98005177402162, 93.01050708085884, 92.91914116034718, 92.96482412060301, 92.99527942744024, 92.99527942744024, 92.98005177402162, 93.02573473427745, 92.98005177402162, 93.05619004111466, 93.02573473427745, 92.98005177402162, 93.01050708085884, 92.99527942744024, 93.02573473427745, 93.1323283082077, 93.05619004111466, 93.19323892188214, 96.13217603167352, 97.07629054362724, 98.27927516369728, 98.46200700472058, 99.05588548804629, 99.19293436881377, 99.46703213034871, 99.55839805086036, 99.75635754530227, 99.78681285213949, 99.89340642606975, 99.89340642606975, 99.9847723465814, 99.96954469316279, 99.9847723465814, 99.9847723465814, 100.0, 99.9847723465814, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]

    
Testacc = [80.71625344352617, 86.08815426997245, 88.01652892561982, 87.80991735537191, 88.4297520661157, 88.7741046831956,
          88.4297520661157,89.11845730027548, 89.25619834710744,89.46280991735537, 89.8760330578512, 89.669421487603, 90.2203856749311, 90.2892561983471, 90.426997245179, 90.495867768595, 90.426997245179, 90.426997245179, 90.564738292011, 90.426997245179, 90.63360881542, 90.495867768595, 90.7713498622589, 90.564738292011, 90.7024793388429, 90.7713498622589, 90.7713498622589, 90.8402203856749, 90.7713498622589, 90.7713498622589, 91.1845730027548, 91.4600550964187, 91.4600550964187, 91.6666666666666, 91.6666666666666, 91.7355371900826, 91.7355371900826, 91.6666666666666, 91.7355371900826, 91.6666666666666, 91.7355371900826, 91.8044077134986, 91.6666666666666, 91.873278236914, 91.7355371900826, 91.8044077134986, 91.6666666666666, 91.873278236914, 91.7355371900826, 91.6666666666666, 91.5289256198347, 93.2506887052341, 93.0440771349862, 93.3884297520661, 93.457300275482, 93.732782369146, 93.457300275482, 93.595041322314, 93.3884297520661, 93.66391184573, 93.1818181818181, 93.66391184573, 93.457300275482, 93.8016528925619, 93.457300275482, 94.077134986225, 93.8705234159779, 93.8705234159779, 93.8705234159779, 93.8705234159779, 94.0082644628099, 93.8705234159779, 94.0082644628099, 93.9393939393939, 94.0082644628099, 93.9393939393939, 94.0082644628099, 93.8705234159779, 94.0082644628099, 93.8705234159779, 94.077134986225, 94.077134986225, 94.0082644628099, 94.0082644628099, 94.077134986225, 94.0082644628099, 94.0082644628099, 94.0082644628099, 94.077134986225, 94.0082644628099, 94.077134986225, 94.077134986225, 94.077134986225, 93.8705234159779, 94.0082644628099, 93.9393939393939, 94.0082644628099, 93.66391184573, 93.8016528925619, 93.8705234159779, 93.732782369146, 93.8016528925619, 93.66391184573, 93.732782369146, 93.732782369146, 93.3884297520661, 93.3884297520661, 93.3884297520661, 93.2506887052341, 93.732782369146, 93.112947658402, 93.457300275482, 93.1818181818181, 93.457300275482, 93.112947658402, 93.8016528925619, 93.0440771349862, 93.526170798898, 92.9063360881542, 93.526170798898, 92.7685950413223, 93.457300275482, 93.0440771349862, 93.457300275482, 93.0440771349862, 93.3884297520661, 93.112947658402, 93.1818181818181, 92.6308539944903, 93.3195592286501, 92.6997245179063, 92.7685950413223, 92.6997245179063, 92.7685950413223, 92.9063360881542, 93.1818181818181, 92.8374655647382, 93.112947658402, 92.7685950413223, 92.7685950413223, 92.6997245179063, 92.5619834710743, 92.6997245179063, 92.493112947658, 92.5619834710743, 92.8374655647382, 92.4242424242424, 92.6308539944903, 92.4242424242424]

import numpy as np
from matplotlib import pyplot
pyplot.plot(np.log(Trainacc))
pyplot.plot(np.log(Testacc))

pyplot.legend(('Training accuracy','Test accuracy'),loc = 4)
    
pyplot.xlabel('Epoch')
pyplot.show()
            
#Train = []
#Test = []
#
#File = open('C:/Users/aashi/Desktop/Python conversion/Plot.txt')
#for line in File :
#    if len(line) >15:
#        i = 0;
#        for word in line.split():
#            
#            if word[0] == '(' and i%2 == 0 :
#                Train.append(float(word[1:-2]))
#                i+=1
#            elif word[0] == '(' and i%2 != 0 :
#                Test.append(float(word[1:-2]))
#                
#print(Train)
#print(Test)
  

          
                       
